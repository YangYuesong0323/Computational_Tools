{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Customer Database\n",
    "**This is the first of three mandatory projects to be handed in as part of the assessment for the course 02807 Computational Tools for Data Science at Technical University of Denmark, autumn 2019.**\n",
    "\n",
    "#### Practical info\n",
    "- **The project is to be done in groups of at most 3 students**\n",
    "- **Each group has to hand in _one_ Jupyter notebook (this notebook) with their solution**\n",
    "- **The hand-in of the notebook is due 2019-10-13, 23:59 on DTU Inside**\n",
    "\n",
    "#### Your solution\n",
    "- **Your solution should be in Python**\n",
    "- **For each question you may use as many cells for your solution as you like**\n",
    "- **You should document your solution and explain the choices you've made (for example by using multiple cells and use Markdown to assist the reader of the notebook)**\n",
    "- **You should not remove the problem statements, and you should not modify the structure of the notebook**\n",
    "- **Your notebook should be runnable, i.e., clicking [>>] in Jupyter should generate the result that you want to be assessed**\n",
    "- **You are not expected to use machine learning to solve any of the exercises**\n",
    "- **You will be assessed according to correctness and readability of your code, choice of solution, choice of tools and libraries, and documentation of your solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Your team has been hired by the company X as data scientists. X makes gadgets for a wide range of industrial and commercial clients.\n",
    "\n",
    "As in-house data scientists, your teams first task, as per request from your new boss, is to optimize business operations. You have decided that a good first step would be to analyze the companys historical sales data to gain a better understanding of where profit is coming from. It may also reveal some low hanging fruit in terms of business opportunities.\n",
    "\n",
    "To get started, you have called the IT department to get access to the customer and sales transactions database. To your horror you've been told that such a database doens't exist, and the only record of sales transactions is kept by John from finance in an Excel spreadsheet. So you've emailed John asking for a CSV dump of the spreadsheet...\n",
    "\n",
    "In this project you need to clean the data you got from John, enrich it with further data, prepare a database for the data, and do some data analysis. The project is comprised of five parts. They are intended to be solved in the order they appear, but it is highly recommended that you read through all of them and devise an overall strategy before you start implementing anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Cleaning the data\n",
    "John has emailed you the following link to the CSV dump you requested.\n",
    "\n",
    "- [transactions.csv](https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv)\n",
    "\n",
    "It seems as though he has been a bit sloppy when keeping the records. \n",
    "\n",
    "In this part you should:\n",
    "- Explain what the data is\n",
    "- Clean it to prepare it for inserting into a database and doing data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import bottleneck as bn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/patrickcording/02807-comp-tools/master/docker/work/data/transactions.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79€</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60505-2867</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>187.99€</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24385-268</td>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>221.73€</td>\n",
       "      <td>2016-01-02 00:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76117-001</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>1075.82€</td>\n",
       "      <td>2016-01-02 02:32:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44946-1046</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>412.55€</td>\n",
       "      <td>2016-01-02 04:51:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         part        company country          city     price  \\\n",
       "0  54868-5165  Chatterbridge   Spain     Barcelona   784.79€   \n",
       "1  60505-2867           Lajo  Greece  Thessaloniki   187.99€   \n",
       "2   24385-268      Flipstorm  Greece        Athens   221.73€   \n",
       "3   76117-001    Twitterbeat  France        Annecy  1075.82€   \n",
       "4  44946-1046  Chatterbridge   Spain     Barcelona   412.55€   \n",
       "\n",
       "                  date  \n",
       "0  2016-01-02 00:01:05  \n",
       "1  2016-01-02 00:05:26  \n",
       "2  2016-01-02 00:18:30  \n",
       "3  2016-01-02 02:32:30  \n",
       "4  2016-01-02 04:51:55  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20558</td>\n",
       "      <td>20568</td>\n",
       "      <td>18397</td>\n",
       "      <td>20535</td>\n",
       "      <td>20567</td>\n",
       "      <td>20568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>19214</td>\n",
       "      <td>20552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>17156-617</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora\\t</td>\n",
       "      <td>-</td>\n",
       "      <td>10/04/2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>300</td>\n",
       "      <td>2795</td>\n",
       "      <td>7383</td>\n",
       "      <td>2787</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             part     company   country       city  price        date\n",
       "count       20558       20568     18397      20535  20567       20568\n",
       "unique        100          35        13         30  19214       20552\n",
       "top     17156-617  Thoughtmix  Portugal  Amadora\\t      -  10/04/2017\n",
       "freq          300        2795      7383       2787      5           7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "part       object\n",
       "company    object\n",
       "country    object\n",
       "city       object\n",
       "price      object\n",
       "date       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type in part is <class 'str'>.\n",
      "Data type in company is <class 'str'>.\n",
      "Data type in country is <class 'str'>.\n",
      "Data type in city is <class 'str'>.\n",
      "Data type in price is <class 'str'>.\n",
      "Data type in date is <class 'str'>.\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(\"Data type in {} is {}.\".format(column,type(df[column][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# check for empty string\n",
    "for column in df.columns:\n",
    "    print(\"\" in df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column part has 10 null value\n",
      "column company has 0 null value\n",
      "column country has 2171 null value\n",
      "column city has 33 null value\n",
      "column price has 1 null value\n",
      "column date has 0 null value\n"
     ]
    }
   ],
   "source": [
    "# check for NaN\n",
    "for column in df.columns:\n",
    "    print(\"column {} has {} null value\".format(column, df[column].isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.part.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17156-617     300\n",
       "37205-992     295\n",
       "52959-433     293\n",
       "0268-6107     293\n",
       "54868-0823    292\n",
       "Name: part, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.part.value_counts(dropna = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### handle missing values in `part`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14916</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yozio</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Patras</td>\n",
       "      <td>518.38€</td>\n",
       "      <td>2018-02-17 21:43:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14917</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Braga</td>\n",
       "      <td>957.24€</td>\n",
       "      <td>2018-02-17 22:12:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14918</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>966.06€</td>\n",
       "      <td>2018-02-17 22:54:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14919</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Roodel</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Aranhas</td>\n",
       "      <td>873.65€</td>\n",
       "      <td>2018-02-17 23:36:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17524</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yozio</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Patras</td>\n",
       "      <td>627.32€</td>\n",
       "      <td>2018-07-12 03:28:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17525</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora\\t</td>\n",
       "      <td>825.8€</td>\n",
       "      <td>2018-07-12 05:34:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17526</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Gabcube</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Almada</td>\n",
       "      <td>188.31€</td>\n",
       "      <td>2018-07-12 06:49:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17527</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Buzzbean</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>429.67€</td>\n",
       "      <td>2018-07-12 07:03:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17528</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Zoonder</td>\n",
       "      <td>United States</td>\n",
       "      <td>Boston</td>\n",
       "      <td>$521.72</td>\n",
       "      <td>2018-07-12 08:38:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17529</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>1031.46€</td>\n",
       "      <td>2018-07-12 09:48:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      part      company        country          city     price  \\\n",
       "14916  NaN        Yozio         Greece        Patras   518.38€   \n",
       "14917  NaN  Brainsphere       Portugal         Braga   957.24€   \n",
       "14918  NaN         Lajo         Greece  Thessaloniki   966.06€   \n",
       "14919  NaN       Roodel       Portugal       Aranhas   873.65€   \n",
       "17524  NaN        Yozio         Greece        Patras   627.32€   \n",
       "17525  NaN   Thoughtmix       Portugal     Amadora\\t    825.8€   \n",
       "17526  NaN      Gabcube       Portugal        Almada   188.31€   \n",
       "17527  NaN     Buzzbean        Germany    Düsseldorf   429.67€   \n",
       "17528  NaN      Zoonder  United States        Boston   $521.72   \n",
       "17529  NaN  Twitterbeat         France        Annecy  1031.46€   \n",
       "\n",
       "                      date  \n",
       "14916  2018-02-17 21:43:43  \n",
       "14917  2018-02-17 22:12:24  \n",
       "14918  2018-02-17 22:54:49  \n",
       "14919  2018-02-17 23:36:52  \n",
       "17524  2018-07-12 03:28:46  \n",
       "17525  2018-07-12 05:34:07  \n",
       "17526  2018-07-12 06:49:44  \n",
       "17527  2018-07-12 07:03:50  \n",
       "17528  2018-07-12 08:38:56  \n",
       "17529  2018-07-12 09:48:17  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.part.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004861921431349669"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_nan_part = len(df[df.part.isnull()])/len(df)\n",
    "prop_nan_part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the proportion of missing values in the part column is only 0.049% of the entire dataset, we can remove the rows with missing part entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['part'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [part, company, country, city, price, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.part.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### company column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean strings in `company`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chatterbridge', 'Lajo', 'Flipstorm', 'Twitterbeat', 'Voomm',\n",
       "       'Buzzbean', 'Zooxo', 'Brainsphere', 'Thoughtmix', 'Wordify',\n",
       "       'Teklist', 'Avaveo', 'Ntags', 'Innojam', 'Shufflebeat', 'Zoonder',\n",
       "       'Kanoodle', 'Gabcube', 'Roodel', 'Riffpath', 'Eimbee', 'Yozio',\n",
       "       'Rhycero', 'Realpoint', 'Gabtune', 'Bubblemix', 'Gevee', 'Tagtune',\n",
       "       'Zooxo.', 'Laj0', 'Ntagz', ' -', ' a', 'aa', 'Thoughtmixz'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.company.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thoughtmix       2794\n",
       "Twitterbeat      2267\n",
       "Zooxo            1670\n",
       "Chatterbridge    1589\n",
       "Shufflebeat      1553\n",
       "Ntags            1514\n",
       "Buzzbean         1253\n",
       "Brainsphere      1241\n",
       "Flipstorm        1193\n",
       "Wordify           968\n",
       "Yozio             653\n",
       "Roodel            626\n",
       "Eimbee            498\n",
       "Zoonder           453\n",
       "Teklist           428\n",
       "Gabcube           356\n",
       "Voomm             250\n",
       "Lajo              219\n",
       "Avaveo            212\n",
       "Rhycero           204\n",
       "Realpoint         158\n",
       "Riffpath          151\n",
       "Kanoodle          127\n",
       "Bubblemix          54\n",
       "Innojam            44\n",
       "Gevee              36\n",
       "Gabtune            27\n",
       "Tagtune            12\n",
       "Zooxo.              2\n",
       "aa                  1\n",
       "Laj0                1\n",
       " a                  1\n",
       "Ntagz               1\n",
       " -                  1\n",
       "Thoughtmixz         1\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.company.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result, it can be seen that some erroneous company names/poorly formatted company names. These include:\n",
    "* ` a`,`aa`,` -` each has occurred once in the dataset. They are likely to be the erroneous entries. Simply remove them.\n",
    "* `Laj0` should be standardized to `Lajo`. Likewise, `Zooxo.` should be standardized to `Zooxo`; `Thoughtmixz` should be standardized to `Thoughtmix`; `Ntagz` should be standardized to `Ntags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.company = df.company.replace([' a','aa',' -'], '')\n",
    "df=df[df.company != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.company = df.company.replace('Zooxo.','Zooxo')\n",
    "df.company = df.company.replace('Laj0','Lajo')\n",
    "df.company = df.company.replace('Thoughtmixz','Thoughtmix')\n",
    "df.company = df.company.replace('Ntagz','Ntags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Thoughtmix       2795\n",
       "Twitterbeat      2267\n",
       "Zooxo            1672\n",
       "Chatterbridge    1589\n",
       "Shufflebeat      1553\n",
       "Ntags            1515\n",
       "Buzzbean         1253\n",
       "Brainsphere      1241\n",
       "Flipstorm        1193\n",
       "Wordify           968\n",
       "Yozio             653\n",
       "Roodel            626\n",
       "Eimbee            498\n",
       "Zoonder           453\n",
       "Teklist           428\n",
       "Gabcube           356\n",
       "Voomm             250\n",
       "Lajo              220\n",
       "Avaveo            212\n",
       "Rhycero           204\n",
       "Realpoint         158\n",
       "Riffpath          151\n",
       "Kanoodle          127\n",
       "Bubblemix          54\n",
       "Innojam            44\n",
       "Gevee              36\n",
       "Gabtune            27\n",
       "Tagtune            12\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.company.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [part, company, country, city, price, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['company'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### country column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean strings in `country`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Spain', 'Greece', 'France', 'Germany', 'United Kingdom',\n",
       "       'Portugal', 'United States', 'Netherlands', 'Japan', 'Switzerland',\n",
       "       nan, 'US', 'Tyskland', 'Portuga'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `unique()` result, we can see that `United States` and `US` are the same and thus should be standardized. \n",
    "<br>\n",
    "Similarly, `Portugal` and `Portuga` should be standardized. \n",
    "<br>\n",
    "Additionally, `Tyskland` means `Germany` in Swedish. Thus they need to be standardized too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country = df.country.replace('US', 'United States')\n",
    "df.country = df.country.replace('Portuga', 'Portugal')\n",
    "df.country = df.country.replace('Tyskland', 'Germany')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Spain', 'Greece', 'France', 'Germany', 'United Kingdom',\n",
       "       'Portugal', 'United States', 'Netherlands', 'Japan', 'Switzerland',\n",
       "       nan], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### handle missing values in  `country` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>52380-1102</td>\n",
       "      <td>Teklist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnhem</td>\n",
       "      <td>357.78</td>\n",
       "      <td>2016-04-21 04:07:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>52125-136</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Braga</td>\n",
       "      <td>493.94€</td>\n",
       "      <td>2016-05-10 11:13:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>16714-295</td>\n",
       "      <td>Teklist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arnhem</td>\n",
       "      <td>624.4€</td>\n",
       "      <td>2016-05-10 21:57:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>76335-006</td>\n",
       "      <td>Buzzbean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Düsseldorf</td>\n",
       "      <td>355.24€</td>\n",
       "      <td>2016-05-12 15:17:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>54473-578</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Braga</td>\n",
       "      <td>123.32€</td>\n",
       "      <td>2016-07-01 01:09:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part      company country        city    price  \\\n",
       "2528  52380-1102      Teklist     NaN      Arnhem   357.78   \n",
       "2947   52125-136  Brainsphere     NaN       Braga  493.94€   \n",
       "2956   16714-295      Teklist     NaN      Arnhem   624.4€   \n",
       "2994   76335-006     Buzzbean     NaN  Düsseldorf  355.24€   \n",
       "3948   54473-578  Brainsphere     NaN       Braga  123.32€   \n",
       "\n",
       "                     date  \n",
       "2528  2016-04-21 04:07:31  \n",
       "2947  2016-05-10 11:13:43  \n",
       "2956  2016-05-10 21:57:15  \n",
       "2994  2016-05-12 15:17:37  \n",
       "3948  2016-07-01 01:09:40  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.country.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2171"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.country.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1056190707856969"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_nan_country = len(df[df.country.isnull()])/len(df)\n",
    "prop_nan_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the fraction of missing values in the country column is 10.43% of the entire dataset which is considerably large, we cannot simply remove the rows with missing countries entries as doing so will result in much information being lost.\n",
    "<br>\n",
    "<br>\n",
    "Instead, we can deduce some of the country names from their corresponding cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city       country \n",
       "Almada     Portugal     323\n",
       "           NaN           33\n",
       "Amadora\\t  Portugal    2511\n",
       "           NaN          275\n",
       "Amiens     France       452\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['city'])['country'].value_counts(dropna = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Almada': 'Portugal',\n",
       " 'Amadora\\t': 'Portugal',\n",
       " 'Amiens': 'France',\n",
       " 'Amsterdam': 'Netherlands',\n",
       " 'Annecy': 'France',\n",
       " 'Aranhas': 'Portugal',\n",
       " 'Arcueil': 'France',\n",
       " 'Arnhem': 'Netherlands',\n",
       " 'Asaka': 'Japan',\n",
       " 'Athens': 'Greece',\n",
       " 'Barcelona': 'Spain',\n",
       " 'Boston': 'United States',\n",
       " 'Braga': 'Portugal',\n",
       " 'Champagnole': 'France',\n",
       " 'Düsseldorf': 'Germany',\n",
       " 'Heraklion': 'Greece',\n",
       " 'Lisbon': 'Portugal',\n",
       " 'London': 'United Kingdom',\n",
       " 'Lyon': 'France',\n",
       " 'Monção': 'Portugal',\n",
       " 'Nanterre': 'France',\n",
       " 'New York': 'United States',\n",
       " 'Nice': 'France',\n",
       " 'Niihama': 'Japan',\n",
       " 'Paris': 'France',\n",
       " 'Patras': 'Greece',\n",
       " 'Porto': 'Portugal',\n",
       " 'Thessaloniki': 'Greece',\n",
       " 'Vila Fria': 'Portugal',\n",
       " 'Zürich': 'Switzerland'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_country_mapping = df.groupby(['city'])['country'].apply(lambda grp: list(grp.value_counts().index)[0]).to_dict()\n",
    "city_country_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 2528,  2947,  2956,  2994,  3948,  3949,  3950,  3951,  3952,\n",
       "             3953,\n",
       "            ...\n",
       "            12843, 12978, 13721, 14438, 16146, 16147, 16148, 16149, 16150,\n",
       "            16151],\n",
       "           dtype='int64', length=2171)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.country.isnull()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_countries(row):\n",
    "    try:\n",
    "        res=city_country_mapping[row.city]\n",
    "    except KeyError:\n",
    "        res=float('NaN')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country = df.apply(impute_countries, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.country.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>68462-565</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057.85€</td>\n",
       "      <td>2016-05-20 08:59:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>54092-515</td>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>772.92€</td>\n",
       "      <td>2016-05-20 09:55:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>0185-0373</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012.8€</td>\n",
       "      <td>2016-05-20 10:42:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12820</th>\n",
       "      <td>50563-113</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>507.49€</td>\n",
       "      <td>2017-10-20 04:03:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12821</th>\n",
       "      <td>55154-5057</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>421.64€</td>\n",
       "      <td>2017-10-20 13:23:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12822</th>\n",
       "      <td>36987-1697</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>937.08€</td>\n",
       "      <td>2017-10-20 18:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12823</th>\n",
       "      <td>68462-565</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>777.58€</td>\n",
       "      <td>2017-10-20 21:21:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12824</th>\n",
       "      <td>0603-6134</td>\n",
       "      <td>Yozio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>775.05€</td>\n",
       "      <td>2017-10-20 23:17:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12825</th>\n",
       "      <td>58118-5060</td>\n",
       "      <td>Yozio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.53€</td>\n",
       "      <td>2017-10-20 23:49:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12826</th>\n",
       "      <td>51060-032</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.36€</td>\n",
       "      <td>2017-10-21 00:11:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12827</th>\n",
       "      <td>16714-295</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.26€</td>\n",
       "      <td>2017-10-21 01:24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12828</th>\n",
       "      <td>0603-6134</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714.66€</td>\n",
       "      <td>2017-10-21 01:53:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12829</th>\n",
       "      <td>52125-136</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>£616.08</td>\n",
       "      <td>2017-10-21 04:26:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12830</th>\n",
       "      <td>70253-307</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>880.07€</td>\n",
       "      <td>2017-10-21 06:19:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12831</th>\n",
       "      <td>49967-724</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>593.0€</td>\n",
       "      <td>2017-10-21 08:04:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12832</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Zoonder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$879.56</td>\n",
       "      <td>2017-10-21 09:35:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12833</th>\n",
       "      <td>65044-3014</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>£738.09</td>\n",
       "      <td>2017-10-21 10:17:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12834</th>\n",
       "      <td>51346-145</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>939.35€</td>\n",
       "      <td>2017-10-21 15:06:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12835</th>\n",
       "      <td>36987-1697</td>\n",
       "      <td>Wordify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$371.3</td>\n",
       "      <td>2017-10-21 15:59:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>63629-2733</td>\n",
       "      <td>Teklist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>236.48€</td>\n",
       "      <td>2017-10-21 17:14:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12837</th>\n",
       "      <td>49035-530</td>\n",
       "      <td>Teklist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1160.47€</td>\n",
       "      <td>2017-10-21 22:49:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12838</th>\n",
       "      <td>62670-4404</td>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>517.91€</td>\n",
       "      <td>2017-10-22 02:54:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12839</th>\n",
       "      <td>0185-0373</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1007.71€</td>\n",
       "      <td>2017-10-22 04:16:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12840</th>\n",
       "      <td>49967-724</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>586.71€</td>\n",
       "      <td>2017-10-22 04:34:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12841</th>\n",
       "      <td>59779-601</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171.8€</td>\n",
       "      <td>2017-10-22 05:00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12842</th>\n",
       "      <td>35356-325</td>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436.67€</td>\n",
       "      <td>2017-10-22 05:10:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12843</th>\n",
       "      <td>49349-471</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1030.42€</td>\n",
       "      <td>2017-10-22 07:11:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16146</th>\n",
       "      <td>58596-001</td>\n",
       "      <td>Wordify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$492.17</td>\n",
       "      <td>2018-04-26 08:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16147</th>\n",
       "      <td>36800-952</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>358.03€</td>\n",
       "      <td>2018-04-26 08:16:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16148</th>\n",
       "      <td>51346-126</td>\n",
       "      <td>Kanoodle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>¥15949.24</td>\n",
       "      <td>2018-04-26 16:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16149</th>\n",
       "      <td>49348-574</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>295.01€</td>\n",
       "      <td>2018-04-26 19:16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16150</th>\n",
       "      <td>0228-2167</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>£682.83</td>\n",
       "      <td>2018-04-26 22:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16151</th>\n",
       "      <td>13537-259</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>865.37€</td>\n",
       "      <td>2018-04-26 22:34:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             part      company country city      price                 date\n",
       "3136    68462-565  Brainsphere     NaN  NaN   1057.85€  2016-05-20 08:59:53\n",
       "3137    54092-515  Shufflebeat     NaN  NaN    772.92€  2016-05-20 09:55:24\n",
       "3138    0185-0373  Brainsphere     NaN  NaN    1012.8€  2016-05-20 10:42:10\n",
       "12820   50563-113        Ntags     NaN  NaN    507.49€  2017-10-20 04:03:11\n",
       "12821  55154-5057  Brainsphere     NaN  NaN    421.64€  2017-10-20 13:23:34\n",
       "12822  36987-1697        Ntags     NaN  NaN    937.08€  2017-10-20 18:25:00\n",
       "12823   68462-565   Thoughtmix     NaN  NaN    777.58€  2017-10-20 21:21:18\n",
       "12824   0603-6134        Yozio     NaN  NaN    775.05€  2017-10-20 23:17:59\n",
       "12825  58118-5060        Yozio     NaN  NaN    157.53€  2017-10-20 23:49:53\n",
       "12826   51060-032   Thoughtmix     NaN  NaN    176.36€  2017-10-21 00:11:55\n",
       "12827   16714-295  Twitterbeat     NaN  NaN    348.26€  2017-10-21 01:24:52\n",
       "12828   0603-6134        Ntags     NaN  NaN    714.66€  2017-10-21 01:53:26\n",
       "12829   52125-136        Zooxo     NaN  NaN    £616.08  2017-10-21 04:26:42\n",
       "12830   70253-307   Thoughtmix     NaN  NaN    880.07€  2017-10-21 06:19:34\n",
       "12831   49967-724        Ntags     NaN  NaN     593.0€  2017-10-21 08:04:12\n",
       "12832  54868-5165      Zoonder     NaN  NaN    $879.56  2017-10-21 09:35:27\n",
       "12833  65044-3014        Zooxo     NaN  NaN    £738.09  2017-10-21 10:17:08\n",
       "12834   51346-145  Brainsphere     NaN  NaN    939.35€  2017-10-21 15:06:59\n",
       "12835  36987-1697      Wordify     NaN  NaN     $371.3  2017-10-21 15:59:29\n",
       "12836  63629-2733      Teklist     NaN  NaN    236.48€  2017-10-21 17:14:47\n",
       "12837   49035-530      Teklist     NaN  NaN   1160.47€  2017-10-21 22:49:57\n",
       "12838  62670-4404  Shufflebeat     NaN  NaN    517.91€  2017-10-22 02:54:15\n",
       "12839   0185-0373   Thoughtmix     NaN  NaN   1007.71€  2017-10-22 04:16:08\n",
       "12840   49967-724   Thoughtmix     NaN  NaN    586.71€  2017-10-22 04:34:36\n",
       "12841   59779-601        Ntags     NaN  NaN     171.8€  2017-10-22 05:00:42\n",
       "12842   35356-325  Shufflebeat     NaN  NaN    436.67€  2017-10-22 05:10:16\n",
       "12843   49349-471        Ntags     NaN  NaN   1030.42€  2017-10-22 07:11:01\n",
       "16146   58596-001      Wordify     NaN  NaN    $492.17  2018-04-26 08:00:25\n",
       "16147   36800-952   Thoughtmix     NaN  NaN    358.03€  2018-04-26 08:16:56\n",
       "16148   51346-126     Kanoodle     NaN  NaN  ¥15949.24  2018-04-26 16:21:00\n",
       "16149   49348-574   Thoughtmix     NaN  NaN    295.01€  2018-04-26 19:16:45\n",
       "16150   0228-2167        Zooxo     NaN  NaN    £682.83  2018-04-26 22:20:00\n",
       "16151   13537-259   Thoughtmix     NaN  NaN    865.37€  2018-04-26 22:34:15"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.country.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### city column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### clean strings in `city`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Barcelona', 'Thessaloniki', 'Athens', 'Annecy', 'Paris',\n",
       "       'Düsseldorf', 'London', 'Braga', 'Nanterre', 'Amadora\\t',\n",
       "       'New York', 'Arnhem', 'Nice', 'Lisbon', 'Amsterdam', 'Porto',\n",
       "       'Boston', 'Niihama', 'Almada', 'Aranhas', 'Heraklion', 'Amiens',\n",
       "       'Patras', 'Arcueil', 'Lyon', 'Asaka', 'Champagnole', 'Zürich', nan,\n",
       "       'Monção', 'Vila Fria'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.city.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result from `unique()` shows that there is an additional `\\t` in the city `Amadora`. Remove the`\\t`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.city = df.city.str.replace(\"\\t\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Barcelona', 'Thessaloniki', 'Athens', 'Annecy', 'Paris',\n",
       "       'Düsseldorf', 'London', 'Braga', 'Nanterre', 'Amadora', 'New York',\n",
       "       'Arnhem', 'Nice', 'Lisbon', 'Amsterdam', 'Porto', 'Boston',\n",
       "       'Niihama', 'Almada', 'Aranhas', 'Heraklion', 'Amiens', 'Patras',\n",
       "       'Arcueil', 'Lyon', 'Asaka', 'Champagnole', 'Zürich', nan, 'Monção',\n",
       "       'Vila Fria'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.city.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### handle missing values in `city`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>68462-565</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057.85€</td>\n",
       "      <td>2016-05-20 08:59:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>54092-515</td>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>772.92€</td>\n",
       "      <td>2016-05-20 09:55:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>0185-0373</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012.8€</td>\n",
       "      <td>2016-05-20 10:42:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12820</th>\n",
       "      <td>50563-113</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>507.49€</td>\n",
       "      <td>2017-10-20 04:03:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12821</th>\n",
       "      <td>55154-5057</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>421.64€</td>\n",
       "      <td>2017-10-20 13:23:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12822</th>\n",
       "      <td>36987-1697</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>937.08€</td>\n",
       "      <td>2017-10-20 18:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12823</th>\n",
       "      <td>68462-565</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>777.58€</td>\n",
       "      <td>2017-10-20 21:21:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12824</th>\n",
       "      <td>0603-6134</td>\n",
       "      <td>Yozio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>775.05€</td>\n",
       "      <td>2017-10-20 23:17:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12825</th>\n",
       "      <td>58118-5060</td>\n",
       "      <td>Yozio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157.53€</td>\n",
       "      <td>2017-10-20 23:49:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12826</th>\n",
       "      <td>51060-032</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>176.36€</td>\n",
       "      <td>2017-10-21 00:11:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12827</th>\n",
       "      <td>16714-295</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348.26€</td>\n",
       "      <td>2017-10-21 01:24:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12828</th>\n",
       "      <td>0603-6134</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>714.66€</td>\n",
       "      <td>2017-10-21 01:53:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12829</th>\n",
       "      <td>52125-136</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>£616.08</td>\n",
       "      <td>2017-10-21 04:26:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12830</th>\n",
       "      <td>70253-307</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>880.07€</td>\n",
       "      <td>2017-10-21 06:19:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12831</th>\n",
       "      <td>49967-724</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>593.0€</td>\n",
       "      <td>2017-10-21 08:04:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12832</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Zoonder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$879.56</td>\n",
       "      <td>2017-10-21 09:35:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12833</th>\n",
       "      <td>65044-3014</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>£738.09</td>\n",
       "      <td>2017-10-21 10:17:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12834</th>\n",
       "      <td>51346-145</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>939.35€</td>\n",
       "      <td>2017-10-21 15:06:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12835</th>\n",
       "      <td>36987-1697</td>\n",
       "      <td>Wordify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$371.3</td>\n",
       "      <td>2017-10-21 15:59:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>63629-2733</td>\n",
       "      <td>Teklist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>236.48€</td>\n",
       "      <td>2017-10-21 17:14:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12837</th>\n",
       "      <td>49035-530</td>\n",
       "      <td>Teklist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1160.47€</td>\n",
       "      <td>2017-10-21 22:49:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12838</th>\n",
       "      <td>62670-4404</td>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>517.91€</td>\n",
       "      <td>2017-10-22 02:54:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12839</th>\n",
       "      <td>0185-0373</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1007.71€</td>\n",
       "      <td>2017-10-22 04:16:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12840</th>\n",
       "      <td>49967-724</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>586.71€</td>\n",
       "      <td>2017-10-22 04:34:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12841</th>\n",
       "      <td>59779-601</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171.8€</td>\n",
       "      <td>2017-10-22 05:00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12842</th>\n",
       "      <td>35356-325</td>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436.67€</td>\n",
       "      <td>2017-10-22 05:10:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12843</th>\n",
       "      <td>49349-471</td>\n",
       "      <td>Ntags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1030.42€</td>\n",
       "      <td>2017-10-22 07:11:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16146</th>\n",
       "      <td>58596-001</td>\n",
       "      <td>Wordify</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$492.17</td>\n",
       "      <td>2018-04-26 08:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16147</th>\n",
       "      <td>36800-952</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>358.03€</td>\n",
       "      <td>2018-04-26 08:16:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16148</th>\n",
       "      <td>51346-126</td>\n",
       "      <td>Kanoodle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>¥15949.24</td>\n",
       "      <td>2018-04-26 16:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16149</th>\n",
       "      <td>49348-574</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>295.01€</td>\n",
       "      <td>2018-04-26 19:16:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16150</th>\n",
       "      <td>0228-2167</td>\n",
       "      <td>Zooxo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>£682.83</td>\n",
       "      <td>2018-04-26 22:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16151</th>\n",
       "      <td>13537-259</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>865.37€</td>\n",
       "      <td>2018-04-26 22:34:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             part      company country city      price                 date\n",
       "3136    68462-565  Brainsphere     NaN  NaN   1057.85€  2016-05-20 08:59:53\n",
       "3137    54092-515  Shufflebeat     NaN  NaN    772.92€  2016-05-20 09:55:24\n",
       "3138    0185-0373  Brainsphere     NaN  NaN    1012.8€  2016-05-20 10:42:10\n",
       "12820   50563-113        Ntags     NaN  NaN    507.49€  2017-10-20 04:03:11\n",
       "12821  55154-5057  Brainsphere     NaN  NaN    421.64€  2017-10-20 13:23:34\n",
       "12822  36987-1697        Ntags     NaN  NaN    937.08€  2017-10-20 18:25:00\n",
       "12823   68462-565   Thoughtmix     NaN  NaN    777.58€  2017-10-20 21:21:18\n",
       "12824   0603-6134        Yozio     NaN  NaN    775.05€  2017-10-20 23:17:59\n",
       "12825  58118-5060        Yozio     NaN  NaN    157.53€  2017-10-20 23:49:53\n",
       "12826   51060-032   Thoughtmix     NaN  NaN    176.36€  2017-10-21 00:11:55\n",
       "12827   16714-295  Twitterbeat     NaN  NaN    348.26€  2017-10-21 01:24:52\n",
       "12828   0603-6134        Ntags     NaN  NaN    714.66€  2017-10-21 01:53:26\n",
       "12829   52125-136        Zooxo     NaN  NaN    £616.08  2017-10-21 04:26:42\n",
       "12830   70253-307   Thoughtmix     NaN  NaN    880.07€  2017-10-21 06:19:34\n",
       "12831   49967-724        Ntags     NaN  NaN     593.0€  2017-10-21 08:04:12\n",
       "12832  54868-5165      Zoonder     NaN  NaN    $879.56  2017-10-21 09:35:27\n",
       "12833  65044-3014        Zooxo     NaN  NaN    £738.09  2017-10-21 10:17:08\n",
       "12834   51346-145  Brainsphere     NaN  NaN    939.35€  2017-10-21 15:06:59\n",
       "12835  36987-1697      Wordify     NaN  NaN     $371.3  2017-10-21 15:59:29\n",
       "12836  63629-2733      Teklist     NaN  NaN    236.48€  2017-10-21 17:14:47\n",
       "12837   49035-530      Teklist     NaN  NaN   1160.47€  2017-10-21 22:49:57\n",
       "12838  62670-4404  Shufflebeat     NaN  NaN    517.91€  2017-10-22 02:54:15\n",
       "12839   0185-0373   Thoughtmix     NaN  NaN   1007.71€  2017-10-22 04:16:08\n",
       "12840   49967-724   Thoughtmix     NaN  NaN    586.71€  2017-10-22 04:34:36\n",
       "12841   59779-601        Ntags     NaN  NaN     171.8€  2017-10-22 05:00:42\n",
       "12842   35356-325  Shufflebeat     NaN  NaN    436.67€  2017-10-22 05:10:16\n",
       "12843   49349-471        Ntags     NaN  NaN   1030.42€  2017-10-22 07:11:01\n",
       "16146   58596-001      Wordify     NaN  NaN    $492.17  2018-04-26 08:00:25\n",
       "16147   36800-952   Thoughtmix     NaN  NaN    358.03€  2018-04-26 08:16:56\n",
       "16148   51346-126     Kanoodle     NaN  NaN  ¥15949.24  2018-04-26 16:21:00\n",
       "16149   49348-574   Thoughtmix     NaN  NaN    295.01€  2018-04-26 19:16:45\n",
       "16150   0228-2167        Zooxo     NaN  NaN    £682.83  2018-04-26 22:20:00\n",
       "16151   13537-259   Thoughtmix     NaN  NaN    865.37€  2018-04-26 22:34:15"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.city.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.city.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Avaveo</th>\n",
       "      <th>France</th>\n",
       "      <th>Nice</th>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Brainsphere</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Portugal</th>\n",
       "      <th>Braga</th>\n",
       "      <td>1236</td>\n",
       "      <td>1236</td>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monção</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bubblemix</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Asaka</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buzzbean</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Düsseldorf</th>\n",
       "      <td>1253</td>\n",
       "      <td>1253</td>\n",
       "      <td>1253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chatterbridge</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Barcelona</th>\n",
       "      <td>1589</td>\n",
       "      <td>1589</td>\n",
       "      <td>1589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eimbee</th>\n",
       "      <th>France</th>\n",
       "      <th>Amiens</th>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Flipstorm</th>\n",
       "      <th>France</th>\n",
       "      <th>Nanterre</th>\n",
       "      <td>381</td>\n",
       "      <td>381</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greece</th>\n",
       "      <th>Athens</th>\n",
       "      <td>812</td>\n",
       "      <td>812</td>\n",
       "      <td>812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gabcube</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Almada</th>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gabtune</th>\n",
       "      <th>France</th>\n",
       "      <th>Lyon</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gevee</th>\n",
       "      <th>France</th>\n",
       "      <th>Champagnole</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Innojam</th>\n",
       "      <th>Netherlands</th>\n",
       "      <th>Amsterdam</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kanoodle</th>\n",
       "      <th>Japan</th>\n",
       "      <th>Niihama</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lajo</th>\n",
       "      <th>Greece</th>\n",
       "      <th>Thessaloniki</th>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ntags</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Lisbon</th>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Realpoint</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Lisbon</th>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhycero</th>\n",
       "      <th>France</th>\n",
       "      <th>Arcueil</th>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Riffpath</th>\n",
       "      <th>Greece</th>\n",
       "      <th>Heraklion</th>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roodel</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Aranhas</th>\n",
       "      <td>626</td>\n",
       "      <td>625</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shufflebeat</th>\n",
       "      <th>Portugal</th>\n",
       "      <th>Porto</th>\n",
       "      <td>1550</td>\n",
       "      <td>1550</td>\n",
       "      <td>1550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tagtune</th>\n",
       "      <th>Switzerland</th>\n",
       "      <th>Zürich</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teklist</th>\n",
       "      <th>Netherlands</th>\n",
       "      <th>Arnhem</th>\n",
       "      <td>426</td>\n",
       "      <td>426</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Thoughtmix</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Portugal</th>\n",
       "      <th>Amadora</th>\n",
       "      <td>2786</td>\n",
       "      <td>2786</td>\n",
       "      <td>2786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vila Fria</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twitterbeat</th>\n",
       "      <th>France</th>\n",
       "      <th>Annecy</th>\n",
       "      <td>2266</td>\n",
       "      <td>2266</td>\n",
       "      <td>2266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voomm</th>\n",
       "      <th>France</th>\n",
       "      <th>Paris</th>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wordify</th>\n",
       "      <th>United States</th>\n",
       "      <th>New York</th>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yozio</th>\n",
       "      <th>Greece</th>\n",
       "      <th>Patras</th>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zoonder</th>\n",
       "      <th>United States</th>\n",
       "      <th>Boston</th>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zooxo</th>\n",
       "      <th>United Kingdom</th>\n",
       "      <th>London</th>\n",
       "      <td>1669</td>\n",
       "      <td>1669</td>\n",
       "      <td>1669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           part  price  date\n",
       "company       country        city                           \n",
       "Avaveo        France         Nice           212    212   212\n",
       "Brainsphere   Portugal       Braga         1236   1236  1236\n",
       "                             Monção           1      1     1\n",
       "Bubblemix     Japan          Asaka           54     54    54\n",
       "Buzzbean      Germany        Düsseldorf    1253   1253  1253\n",
       "Chatterbridge Spain          Barcelona     1589   1589  1589\n",
       "Eimbee        France         Amiens         498    498   498\n",
       "Flipstorm     France         Nanterre       381    381   381\n",
       "              Greece         Athens         812    812   812\n",
       "Gabcube       Portugal       Almada         356    356   356\n",
       "Gabtune       France         Lyon            27     27    27\n",
       "Gevee         France         Champagnole     36     36    36\n",
       "Innojam       Netherlands    Amsterdam       44     44    44\n",
       "Kanoodle      Japan          Niihama        126    126   126\n",
       "Lajo          Greece         Thessaloniki   220    220   220\n",
       "Ntags         Portugal       Lisbon        1509   1509  1509\n",
       "Realpoint     Portugal       Lisbon         158    158   158\n",
       "Rhycero       France         Arcueil        204    204   204\n",
       "Riffpath      Greece         Heraklion      151    151   151\n",
       "Roodel        Portugal       Aranhas        626    625   626\n",
       "Shufflebeat   Portugal       Porto         1550   1550  1550\n",
       "Tagtune       Switzerland    Zürich          12     12    12\n",
       "Teklist       Netherlands    Arnhem         426    426   426\n",
       "Thoughtmix    Portugal       Amadora       2786   2786  2786\n",
       "                             Vila Fria        1      1     1\n",
       "Twitterbeat   France         Annecy        2266   2266  2266\n",
       "Voomm         France         Paris          250    250   250\n",
       "Wordify       United States  New York       966    966   966\n",
       "Yozio         Greece         Patras         651    651   651\n",
       "Zoonder       United States  Boston         452    452   452\n",
       "Zooxo         United Kingdom London        1669   1669  1669"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"company\",\"country\",'city']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001605448795913403"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_nan_city = len(df[df.city.isnull()])/len(df)\n",
    "prop_nan_city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the proportion of missing values in the city column is only 0.16% of the entire dataset, we can remove the rows with missing city entries.\n",
    "<br>\n",
    "<br>\n",
    "Moreover, the table above shows that all but three records have missing values in both country and city. This implies that dropping records that have missing values in the city column does not cause a big loss in information in the country column, since only three such country records are not null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [part, company, country, city, price, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.city.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string to datetime object\n",
    "df['parsed_date'] = pd.to_datetime(df['date'],errors='coerce', infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>parsed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>17156-617</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>791.86€</td>\n",
       "      <td>2016-06-32 07:22:28</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3540</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Shufflebeat</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Porto</td>\n",
       "      <td>525.24€</td>\n",
       "      <td>2016-06-32 08:08:48</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            part      company   country     city    price  \\\n",
       "3539   17156-617   Thoughtmix  Portugal  Amadora  791.86€   \n",
       "3540  54868-5165  Shufflebeat  Portugal    Porto  525.24€   \n",
       "\n",
       "                     date parsed_date  \n",
       "3539  2016-06-32 07:22:28         NaT  \n",
       "3540  2016-06-32 08:08:48         NaT  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking\n",
    "df[df.parsed_date.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### price column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$', '-', '.', 'a', 'd', 'i', 'n', 'o', 'v', '£', '¥', '€'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original intention was to find all currency signs present\n",
    "# but it turned out that there are other poorly formatted cells other than currency signs\n",
    "res=[]\n",
    "for p in df.price:\n",
    "    for c in p:\n",
    "        if c.isdigit() == False:\n",
    "            res.append(c)\n",
    "x=np.array(res)\n",
    "np.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "void\n",
      "void\n",
      "na\n",
      "na\n",
      "na\n"
     ]
    }
   ],
   "source": [
    "# find what are those cells\n",
    "res=[]\n",
    "for p in df.price:\n",
    "    for c in p:\n",
    "        if c in ['a', 'd', 'i', 'n', 'o', 'v']:\n",
    "            print(p)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20519\n",
      "20514\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df=df[df.price != 'void']\n",
    "df=df[df.price != 'na']\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_price(string):\n",
    "    amount=re.match(r'([^-\\d\\.]?)(-?\\d*\\.?\\d*)([\\D]?)', str(string))\n",
    "    lst=[i for i in amount.groups() if i != '']\n",
    "#     if len(lst) != 2:\n",
    "#         return float('NaN')\n",
    "    try:\n",
    "        res=float(lst[0])\n",
    "    except ValueError:\n",
    "        res=float(lst[1])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_symbol(string):\n",
    "    amount=re.match(r'([^-\\d\\.]?)(-?\\d*\\.?\\d*)([\\D]?)', str(string))\n",
    "    lst=[i for i in amount.groups() if i != '']\n",
    "#     if len(lst) != 2:\n",
    "#         return float('NaN')\n",
    "    try:\n",
    "        number=float(lst[0])\n",
    "        sign=lst[1]\n",
    "    except ValueError:\n",
    "        sign=lst[0]\n",
    "    return sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_currency(string):\n",
    "    currency=re.findall(\"[€$¥£]\",string)\n",
    "    if currency:\n",
    "        symbol=currency[0]\n",
    "        if symbol == \"€\":\n",
    "            return \"EUR\"\n",
    "        elif symbol == \"$\":\n",
    "            return \"USD\"\n",
    "        elif symbol == \"¥\":\n",
    "            return \"CNY\"\n",
    "        elif symbol == \"£\":\n",
    "            return \"GBP\"\n",
    "    else:\n",
    "        print(\"error: can't find currenct symbol in {}\".format(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: can't find currenct symbol in 465.6\n",
      "error: can't find currenct symbol in 1266.68\n",
      "error: can't find currenct symbol in 829.3\n",
      "error: can't find currenct symbol in 357.78\n",
      "error: can't find currenct symbol in -\n",
      "error: can't find currenct symbol in -\n",
      "error: can't find currenct symbol in -\n",
      "error: can't find currenct symbol in -\n",
      "error: can't find currenct symbol in -\n"
     ]
    }
   ],
   "source": [
    "df[\"currency\"]=df.price.apply(find_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['price'] != \"465.6\"]\n",
    "df=df[df['price'] != \"1266.68\"]\n",
    "df=df[df['price'] != \"829.3\"]\n",
    "df=df[df['price'] != \"357.78\"]\n",
    "df=df[df['price'] != \"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_amount']=df.price.apply(parse_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_symbol']=df.price.apply(parse_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>parsed_date</th>\n",
       "      <th>currency</th>\n",
       "      <th>price_amount</th>\n",
       "      <th>price_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20563</th>\n",
       "      <td>21695-267</td>\n",
       "      <td>Roodel</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Aranhas</td>\n",
       "      <td>606.37€</td>\n",
       "      <td>2018-12-31 20:48:14</td>\n",
       "      <td>2018-12-31 20:48:14</td>\n",
       "      <td>EUR</td>\n",
       "      <td>606.37</td>\n",
       "      <td>€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20564</th>\n",
       "      <td>49999-737</td>\n",
       "      <td>Thoughtmix</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Amadora</td>\n",
       "      <td>828.37€</td>\n",
       "      <td>2018-12-31 21:24:17</td>\n",
       "      <td>2018-12-31 21:24:17</td>\n",
       "      <td>EUR</td>\n",
       "      <td>828.37</td>\n",
       "      <td>€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20565</th>\n",
       "      <td>52343-025</td>\n",
       "      <td>Brainsphere</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Braga</td>\n",
       "      <td>686.1€</td>\n",
       "      <td>2018-12-31 21:38:02</td>\n",
       "      <td>2018-12-31 21:38:02</td>\n",
       "      <td>EUR</td>\n",
       "      <td>686.10</td>\n",
       "      <td>€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20566</th>\n",
       "      <td>49288-0285</td>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>1051.08€</td>\n",
       "      <td>2019-02-21 20:05:00</td>\n",
       "      <td>2019-02-21 20:05:00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1051.08</td>\n",
       "      <td>€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20567</th>\n",
       "      <td>43419-018</td>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>139.56€</td>\n",
       "      <td>2019-05-14 22:48:39</td>\n",
       "      <td>2019-05-14 22:48:39</td>\n",
       "      <td>EUR</td>\n",
       "      <td>139.56</td>\n",
       "      <td>€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             part      company   country     city     price  \\\n",
       "20563   21695-267       Roodel  Portugal  Aranhas   606.37€   \n",
       "20564   49999-737   Thoughtmix  Portugal  Amadora   828.37€   \n",
       "20565   52343-025  Brainsphere  Portugal    Braga    686.1€   \n",
       "20566  49288-0285    Flipstorm    Greece   Athens  1051.08€   \n",
       "20567   43419-018    Flipstorm    Greece   Athens   139.56€   \n",
       "\n",
       "                      date         parsed_date currency  price_amount  \\\n",
       "20563  2018-12-31 20:48:14 2018-12-31 20:48:14      EUR        606.37   \n",
       "20564  2018-12-31 21:24:17 2018-12-31 21:24:17      EUR        828.37   \n",
       "20565  2018-12-31 21:38:02 2018-12-31 21:38:02      EUR        686.10   \n",
       "20566  2019-02-21 20:05:00 2019-02-21 20:05:00      EUR       1051.08   \n",
       "20567  2019-05-14 22:48:39 2019-05-14 22:48:39      EUR        139.56   \n",
       "\n",
       "      price_symbol  \n",
       "20563            €  \n",
       "20564            €  \n",
       "20565            €  \n",
       "20566            €  \n",
       "20567            €  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns='date')\n",
    "df.rename(columns={\"parsed_date\" : \"date\", \n",
    "                   \"currency\": \"currency_name\",\n",
    "                   \"price_symbol\":\"currency_symbol\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>company</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>price</th>\n",
       "      <th>date</th>\n",
       "      <th>currency_name</th>\n",
       "      <th>price_amount</th>\n",
       "      <th>currency_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54868-5165</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>784.79€</td>\n",
       "      <td>2016-01-02 00:01:05</td>\n",
       "      <td>EUR</td>\n",
       "      <td>784.79</td>\n",
       "      <td>€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60505-2867</td>\n",
       "      <td>Lajo</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Thessaloniki</td>\n",
       "      <td>187.99€</td>\n",
       "      <td>2016-01-02 00:05:26</td>\n",
       "      <td>EUR</td>\n",
       "      <td>187.99</td>\n",
       "      <td>€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24385-268</td>\n",
       "      <td>Flipstorm</td>\n",
       "      <td>Greece</td>\n",
       "      <td>Athens</td>\n",
       "      <td>221.73€</td>\n",
       "      <td>2016-01-02 00:18:30</td>\n",
       "      <td>EUR</td>\n",
       "      <td>221.73</td>\n",
       "      <td>€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76117-001</td>\n",
       "      <td>Twitterbeat</td>\n",
       "      <td>France</td>\n",
       "      <td>Annecy</td>\n",
       "      <td>1075.82€</td>\n",
       "      <td>2016-01-02 02:32:30</td>\n",
       "      <td>EUR</td>\n",
       "      <td>1075.82</td>\n",
       "      <td>€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44946-1046</td>\n",
       "      <td>Chatterbridge</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>412.55€</td>\n",
       "      <td>2016-01-02 04:51:55</td>\n",
       "      <td>EUR</td>\n",
       "      <td>412.55</td>\n",
       "      <td>€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         part        company country          city     price  \\\n",
       "0  54868-5165  Chatterbridge   Spain     Barcelona   784.79€   \n",
       "1  60505-2867           Lajo  Greece  Thessaloniki   187.99€   \n",
       "2   24385-268      Flipstorm  Greece        Athens   221.73€   \n",
       "3   76117-001    Twitterbeat  France        Annecy  1075.82€   \n",
       "4  44946-1046  Chatterbridge   Spain     Barcelona   412.55€   \n",
       "\n",
       "                 date currency_name  price_amount currency_symbol  \n",
       "0 2016-01-02 00:01:05           EUR        784.79               €  \n",
       "1 2016-01-02 00:05:26           EUR        187.99               €  \n",
       "2 2016-01-02 00:18:30           EUR        221.73               €  \n",
       "3 2016-01-02 02:32:30           EUR       1075.82               €  \n",
       "4 2016-01-02 04:51:55           EUR        412.55               €  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Enriching the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common task for a data scientists is to combine or enrich data from internal sources with data available from external sources. The purpose of this can be either to fix issues with the data or to make it easier to derive insights from the data.\n",
    "\n",
    "In this part you should enrich your data with data from at least one external source. You may look to part 4 for some  inspiration as to what is required. Your solution should be automated, i.e., you can not ask the reader of your notebook to download any data manually. You should argue why and what you expect to achieve by the enrichments you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from forex_python.converter import CurrencyRates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External Data 1 --> Exchange Rate\n",
    "<describe why use this particular external data, how it can enhance the existing dataset, etc.>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CurrencyRates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToUSD(currency,date):\n",
    "    return c.convert(currency, 'USD', 1 , date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='api.ratesapi.io', port=443): Max retries exceeded with url: /api/2016-02-09?base=GBP&symbols=USD&rtype=fpy (Caused by SSLError(SSLError(\"bad handshake: SysCallError(10054, 'WSAECONNRESET')\")))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSysCallError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m                 \u001b[0mcnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1914\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL_do_handshake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1915\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\OpenSSL\\SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[1;34m(self, ssl, result)\u001b[0m\n\u001b[0;32m   1638\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0merrno\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mSysCallError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrorcode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1640\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSysCallError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Unexpected EOF\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSysCallError\u001b[0m: (10054, 'WSAECONNRESET')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             ssl_context=context)\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bad handshake: %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLError\u001b[0m: (\"bad handshake: SysCallError(10054, 'WSAECONNRESET')\",)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 638\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.ratesapi.io', port=443): Max retries exceeded with url: /api/2016-02-09?base=GBP&symbols=USD&rtype=fpy (Caused by SSLError(SSLError(\"bad handshake: SysCallError(10054, 'WSAECONNRESET')\")))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-03f668158aaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mUSD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mToUSD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mUSD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"YAS! I'm done!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-e92d3333b823>\u001b[0m in \u001b[0;36mToUSD\u001b[1;34m(currency, date)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mToUSD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'USD'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\forex_python\\converter.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, base_cur, dest_cur, amount, date_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mpayload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'base'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbase_cur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'symbols'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdest_cur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rtype'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'fpy'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0msource_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_source_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdate_str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_decoded_rate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest_cur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_decimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_decimal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_SSLError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m                 \u001b[1;31m# This branch is for urllib3 v1.22 and later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSSLError\u001b[0m: HTTPSConnectionPool(host='api.ratesapi.io', port=443): Max retries exceeded with url: /api/2016-02-09?base=GBP&symbols=USD&rtype=fpy (Caused by SSLError(SSLError(\"bad handshake: SysCallError(10054, 'WSAECONNRESET')\")))"
     ]
    }
   ],
   "source": [
    "USD=[]\n",
    "dic={}\n",
    "for i in range(len(df)):\n",
    "    if i == 2000:\n",
    "        print(\"I'm 10% done!\")\n",
    "    if i == 5000:\n",
    "        print(\"Hang on, Ms.Pretty/Mr.Handsome. I'm doing my best!\")\n",
    "    if i == 10000:\n",
    "        print(\"Yeah, I'm 50% done!\")\n",
    "    if i == 15000:\n",
    "        print(\"Waiting is boring, why not sing a song? La la la ~\")\n",
    "    if i == 20000:\n",
    "        print(\"Almost there, give me 10s!\")\n",
    "    date=df.iloc[i,5].date()\n",
    "    currency=df.iloc[i,6]\n",
    "    key=(currency,date)\n",
    "    if key in dic:\n",
    "        USD.append(dic[key])\n",
    "    else:\n",
    "        dic[key] = ToUSD(currency,date)\n",
    "        USD.append(dic[key])\n",
    "print(\"YAS! I'm done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['exchange_rate_to_USD'] = USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['standardized_USD'] = df.price_amount * df.exchange_rate_to_USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the above dataframe as a pickle object for easy access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"df.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(df, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External Data 2 --> GDP\n",
    "<describe why use this particular external data, how it can enhance the existing dataset, etc.>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP=pd.read_csv(\"https://raw.githubusercontent.com/YangYuesong0323/Computational_Tools/master/GDP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP=GDP.drop(columns=['Country Code','Indicator Name','Indicator Code'])\n",
    "\n",
    "GDP=GDP.rename(columns={'Country Name':'country'})\n",
    "\n",
    "GDP_long=pd.melt(GDP,id_vars=['country'], var_name='year', value_name='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External Data 3 --> Population\n",
    "<describe why use this particular external data, how it can enhance the existing dataset, etc.>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population=pd.read_csv(\"https://raw.githubusercontent.com/YangYuesong0323/Computational_Tools/master/population.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population=Population.drop(columns=['Country Code','Indicator Name','Indicator Code'])\n",
    "\n",
    "Population=Population.rename(columns={'Country Name':'country'})\n",
    "\n",
    "Population_long=pd.melt(Population,id_vars=['country'], var_name='year', value_name='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Creating a database\n",
    "Storing data in a relational database has the advantages that it is persistent, fast to query, and it will be easier access for other employees at Weyland-Yutani.\n",
    "\n",
    "In this part you should:\n",
    "- Create a database and table(s) for the data\n",
    "- Insert data into the tables\n",
    "\n",
    "You may use SQLite locally to do this. You should argue why you choose to store your data the way you do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a database named `project1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('project1.sqlite')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a table named `customer` from the pandas dataframe `df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the current dataframe `df` does not have a primary key, we create another column called `key` and fill this column with the index of each row, i.e. use the row index as the primary key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"df.pickle\", \"rb\") as output_file:\n",
    "    df = pickle.load(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, 'key', range(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add two additional columns, year and months, to the dataframe `df` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df.date.apply(lambda x : x.year)\n",
    "df['month'] = df.date.apply(lambda x : x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the `customer` table with sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''DROP TABLE IF EXISTS customer;''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''CREATE TABLE IF NOT EXISTS customer(\n",
    "key INTEGER PRIMARY KEY, \n",
    "part varchar(20), \n",
    "company varchar(20), \n",
    "country varchar(30), \n",
    "city varchar(20), \n",
    "price varchar(10), \n",
    "date DATETIME, \n",
    "currency_name varchar(3), \n",
    "price_amount float(10), \n",
    "currency_symbol varchar(1), \n",
    "exchange_rate_to_USD float(10), \n",
    "standardized_USD float(10),\n",
    "year DATETIME,\n",
    "month DATETIME,\n",
    "FOREIGN KEY (company, year) REFERENCES gdp(company, year))''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('customer', conn, if_exists='replace', index=False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to test whether the sqlite table created is the same as the original pandas dataframe\n",
    "\n",
    "c.execute('SELECT Count(*) FROM customer')\n",
    "print('number of rows in the sqlite customer table is {}'.format(c.fetchone()[0]))\n",
    "print('number of rows in the pandas df dataframe is {}'.format(len(df)))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to test whether the sqlite table created is the same as the original pandas dataframe\n",
    "\n",
    "c.execute('SELECT * FROM customer')\n",
    "print('first row in the sqlite customer table is {}'.format(c.fetchone()))\n",
    "print()\n",
    "print('first row in the pandas df dataframe is {}'.format(tuple(df.iloc[0])))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a table named `gdp` from the pandas dataframe `GDP_long`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_long.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''DROP TABLE IF EXISTS gdp;''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the attributes can uniquely identify the row entries. However, we can uniquely identify a row by using `country` and `year` combined. Therefore, we set `country` and `year` as the composite key to the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''CREATE TABLE IF NOT EXISTS gdp( \n",
    "country varchar(64), \n",
    "year varchar(10), \n",
    "value float(10),\n",
    "PRIMARY KEY (country, year))''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDP_long.to_sql('gdp', conn, if_exists='replace', index=False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to test whether the sqlite table created is the same as the original pandas dataframe\n",
    "\n",
    "c.execute('SELECT Count(*) FROM gdp')\n",
    "print('number of rows in the sqlite gdp table is {}'.format(c.fetchone()[0]))\n",
    "print('number of rows in the pandas GDP_long dataframe is {}'.format(len(GDP_long)))\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to test whether the sqlite table created is the same as the original pandas dataframe\n",
    "\n",
    "c.execute('SELECT * FROM gdp')\n",
    "print('first row in the sqlite gdp table is {}'.format(c.fetchone()))\n",
    "print()\n",
    "print('first row in the pandas GDP_long dataframe is {}'.format(tuple(GDP_long.iloc[0])))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a table named `population` from the pandas dataframe `Population_long`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population_long.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''DROP TABLE IF EXISTS population;''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the attributes can uniquely identify the row entries. However, we can uniquely identify a row by using `country` and `year` combined. Therefore, we set `country` and `year` as the composite key to the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('''CREATE TABLE IF NOT EXISTS population(\n",
    "country varchar(64), \n",
    "year varchar(10), \n",
    "value float(10),\n",
    "PRIMARY KEY (country, year))''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Population_long.to_sql('population', conn, if_exists='replace', index=False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to test whether the sqlite table created is the same as the original pandas dataframe\n",
    "\n",
    "c.execute('SELECT Count(*) FROM population')\n",
    "print('number of rows in the sqlite population table is {}'.format(c.fetchone()[0]))\n",
    "print('number of rows in the pandas Population_long dataframe is {}'.format(len(Population_long)))\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to test whether the sqlite table created is the same as the original pandas dataframe\n",
    "\n",
    "c.execute('SELECT * FROM population')\n",
    "print('first row in the sqlite population table is {}'.format(c.fetchone()))\n",
    "print()\n",
    "print('first row in the pandas Population_long dataframe is {}'.format(tuple(Population_long.iloc[0])))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Analyzing the data\n",
    "You are now ready to analyze the data. Your goal is to gain some actionable business insights to present to your boss. \n",
    "\n",
    "In this part, you should ask some questions and try to answer them based on the data. You should write SQL queries to retrieve the data. For each question, you should state why it is relevant and what you expect to find.\n",
    "\n",
    "To get you started, you should prepare answers to the following questions. You should add more questions.\n",
    "#### Who are the most profitable clients?\n",
    "Knowing which clients that generate the most revenue for the company will assist your boss in distributing customer service ressources.\n",
    "\n",
    "#### Are there any clients for which profit is declining?\n",
    "Declining profit from a specific client may indicate that the client is disatisfied with the product. Gaining a new client is often much more work than retaining one. Early warnings about declining profit may help your boss fighting customer churn.\n",
    "\n",
    "\n",
    "Remember, you are taking this to your new boss, so think about how you present the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = \"purple\"> Q1: Who are the most profitable clients?<font>\n",
    "Knowing which clients that generate the most revenue for the company will assist your boss in distributing customer service ressources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To answer this question, we have defined a function `topN` to display the top N companies with the highest total profits, both in tabular and in graphical forms.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes in an integer and return a table and a graph\n",
    "def TopN(num):\n",
    "        \n",
    "    # SQL query to select the top N most profitable companies\n",
    "    c.execute('''\n",
    "    SELECT company, sum(standardized_USD) as ProfitSum\n",
    "    FROM customer\n",
    "    Group By company\n",
    "    Order By ProfitSum DESC\n",
    "    Limit ?\n",
    "    ''', (num,))\n",
    "    \n",
    "    topN_list=c.fetchall()\n",
    "    \n",
    "    # consolidate the result into a pandas dataframe\n",
    "    topN_df = pd.DataFrame(topN_list, columns=['company', 'total profits'])\n",
    "    print(\"The top {} most profitable clients are:\".format(num))\n",
    "    print()\n",
    "    \n",
    "    # print the table\n",
    "    print(topN_df)\n",
    "    \n",
    "    # helper function to decompose the topN_list obtained from the sql query\n",
    "    def decomposeList(index, lst):\n",
    "        return [x[index] for x in lst]\n",
    "    \n",
    "    # a bar plot to visualize the total profits of the top N clients in descending order\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.bar(x=decomposeList(0,topN_list), height=decomposeList(1,topN_list))\n",
    "    plt.title(\"Top {} Clients With The Largest Total Profits\".format(num))\n",
    "    plt.xlabel(\"Client Name\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Total Profit\")  \n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, show the top 5 clients with the largest total profits\n",
    "TopN(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test again, but this time round use N=10\n",
    "TopN(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = \"purple\"> Q2: Are there any clients for which profit is declining?<font>\n",
    "Declining profit from a specific client may indicate that the client is disatisfied with the product. Gaining a new client is often much more work than retaining one. Early warnings about declining profit may help your boss fighting customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 Part 1: Yearly Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The most straightforward approach is to aggregate total yearly profits of each client. We will be able to observe the trend with some visualizations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis is done in three steps:\n",
    "1. Query the database to obtain yearly profits of each client.\n",
    "2. Plot bar graphs to achieve a more direct understanding.\n",
    "3. Conclude on clients with declining profits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "c.execute('''\n",
    "SELECT company, SUM(standardized_USD), year\n",
    "FROM customer\n",
    "GROUP BY company, year\n",
    "''')\n",
    "yearlyAggre=c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the yearly profits of a single client\n",
    "# this function takes in a string which is a client name and return a bar plot\n",
    "def get_one_yearly_plot(name):\n",
    "    \n",
    "    value=[x[1] for x in list(filter(lambda x : x[0] == name, yearlyAggre))]\n",
    "    year=[x[2] for x in list(filter(lambda x : x[0] == name, yearlyAggre))]\n",
    "\n",
    "    plt.bar(x=year, height=value, color = \"#cd7f7d\")\n",
    "    plt.xticks(year, year)\n",
    "    plt.title(\"Yearly Profits of {}\".format(name))\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Total Profits in USD\")\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# use this function when the boss wants to have a closer look at a particular client\n",
    "get_one_yearly_plot('Lajo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the yearly profits of ALL clients at once\n",
    "# this function does not take in any parameter and return plots for all clients\n",
    "def get_all_yearly_plots():    \n",
    "    fig, ax = plt.subplots(7, 4, figsize=(15,15))\n",
    "    plt.subplots_adjust(wspace = 0.8, hspace = 1)\n",
    "    \n",
    "    for index, name in enumerate(df.company.unique()):\n",
    "        \n",
    "        value=[x[1] for x in list(filter(lambda x : x[0] == name, yearlyAggre))]\n",
    "        year=[x[2] for x in list(filter(lambda x : x[0] == name, yearlyAggre))]\n",
    "        \n",
    "        row = index//4\n",
    "        col = index%4\n",
    "        \n",
    "        ax[row, col].set_title(\"Yearly Profits of {}\".format(name))\n",
    "        ax[row, col].set_xlabel(\"Year\")\n",
    "        ax[row, col].set_ylabel(\"Total Profits in USD\")\n",
    "        ax[row, col].bar(x=year, height=value, color = \"#cd7f7d\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "get_all_yearly_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sectional Conclusion: From the yearly trends, it can be seen that the clients with declining profits are: <font color='purple'> Flipstorm, Voomm, Zoonder, Kanoodle and Yozio</font>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2 Part 2: Monthly Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A analytical approach can be more convincing than a visualization approach. Since there are more time steps if monthly interval is adopted, we could treat the data as a Time Series (there are only 3-4 time steps in yearly data which makes them less suitable for time series analysis). Hopefully it will shed more light on which the underperforming clients are.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis is done in several steps:\n",
    "\n",
    "1. Query the database to obtain the time series of each client.\n",
    "2. Plot the monthly profits of each client.\n",
    "3. Calculate and plot the simple moving average profits of each client, based on its original time series.\n",
    "4. Fit a linear line to the moving average time series. Gradient of the fitted line gives us insight into whether a client's profits is on the decline. i.e. if the gradient is negative, the profit of the client is likely to be declining.\n",
    "5. Conclude on clients with declining profits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data from the database\n",
    "c.execute('''\n",
    "SELECT company, year, month, SUM(standardized_USD)\n",
    "FROM customer\n",
    "GROUP BY company, year, month\n",
    "''')\n",
    "\n",
    "Time_Series=c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function that queries the moving average profits and the gradient of the fitted line on the moving average of different clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the profits of a client\n",
    "# this function takes in a client name and returns the corresponding time series data\n",
    "def getCompany(name):\n",
    "    return list(filter(lambda x : x[0]==name, Time_Series))\n",
    "\n",
    "# function to get the monthly moving average of the profits of a certain client\n",
    "def getMA(name):\n",
    "    lst = getCompany(name)\n",
    "    data=[x[3] for x in lst]\n",
    "    ma = bn.move_mean(data, window=3, min_count=3)\n",
    "    ma = ma[2:]\n",
    "    return ma\n",
    "\n",
    "# function to get the gradient of the moving average profits. \n",
    "# This will help us understand whether the profits of a particular client is on the decline (gradient is negative)\n",
    "def getGradient(name):\n",
    "    lst = getCompany(name)\n",
    "    lst=decomposeList(3,lst)\n",
    "    m,b = np.polyfit([x for x in range(len(lst))], lst, 1)\n",
    "    return m\n",
    "\n",
    "# function to list down the gradients of the moving average profits for all companies. \n",
    "def get_all_gradients():\n",
    "    grad_dict = {}\n",
    "    for name in df.company.unique():\n",
    "        grad_dict[name] = getGradient(name)\n",
    "    return grad_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions that plot the actual monthly profits and moving average monthly profits of different clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the monthly profits of a client\n",
    "def get_one_monthly_plot(name):\n",
    "    lst = getCompany(name)\n",
    "    plt.plot(decomposeList(3,lst))\n",
    "    plt.title(\"Monthly Profits of {}\".format(name))\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Total Profits in USD\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# function to plot the moving average of the monthly profits of a client\n",
    "def get_one_monthly_MA_plot(name):\n",
    "    lst = getMA(name)\n",
    "    plt.plot(lst)\n",
    "    plt.title(\"Monthly Moving Average Profits of {}\".format(name))\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Total Profits (MA) in USD')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# function to plot the monthly profits of ALL clients at once\n",
    "def get_all_monthly_plots():    \n",
    "    fig, ax = plt.subplots(7, 4, figsize=(25,15))\n",
    "    plt.subplots_adjust(wspace = 0.2, hspace = 0.7)\n",
    "    \n",
    "    for index, name in enumerate(df.company.unique()):\n",
    "        lst = getCompany(name)\n",
    "        row = index//4\n",
    "        col = index%4\n",
    "        ax[row, col].set_title(\"Monthly Profits of {}\".format(name))\n",
    "        ax[row, col].set_xlabel(\"Year\")\n",
    "        ax[row, col].set_ylabel(\"Total Profits in USD\")\n",
    "        ax[row, col].plot(decomposeList(3,lst))\n",
    "        \n",
    "\n",
    "# function to plot the moving average of the monthly profits of ALL clients at once\n",
    "def get_all_monthly_MA_plots():    \n",
    "    fig, ax = plt.subplots(7, 4, figsize=(25,15))\n",
    "    plt.subplots_adjust(wspace = 0.2, hspace = 0.7)\n",
    "    \n",
    "    for index, name in enumerate(df.company.unique()):\n",
    "        lst = getMA(name)\n",
    "        row = index//4\n",
    "        col = index%4      \n",
    "        ax[row, col].set_title(\"Monthly Moving Average Profits of {}\".format(name))\n",
    "        ax[row, col].set_xlabel(\"Year\")\n",
    "        ax[row, col].set_ylabel(\"Total Profits (MA) in USD\")\n",
    "        ax[row, col].plot(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the profits plot and the moving average plot of a random client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_one_monthly_plot(\"Gabtune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_one_monthly_MA_plot(\"Gabtune\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the gradient of fitted line on the moving average profits of a random company:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getGradient(\"Gabtune\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the actual profits plots for all clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_monthly_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the moving average profits plots for all clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_monthly_MA_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sectional Conclusion: From the moving average plots, it can be seen that the clients with declining profits are: <font color='purple'> Flipstorm, Voomm and Kanoodle</font>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the gradients of the fitted line on moving average profits of all clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MA_gradients = get_all_gradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out which clients' gradients are negative, i.e. identify clients with declining profits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May choose a different treshold for nagativity\n",
    "# Our group feels 50 means a significant decreas\n",
    "Declining = list(filter(lambda x : x[1] < -50, MA_gradients.items()))\n",
    "Declining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Declining_companies = list([x[0] for x in Declining])\n",
    "Declining_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sectional Conclusion: From the gradients, it can be seen that the clients with declining profits are: <font color='red'> Flipstorm, Voomm, Kanoodle and Yozio <font>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall Conclusion: From analysis above, <font color='red'> Flipstorm, Voomm and Kanoodle </font> appear in all sectional conclusions. We identify them as clients with declining profits.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = \"purple\"> Q3: Why did the unprofitable clients identified in Q2 experience a decline in profits? Provide reasons to their decline.</font>\n",
    "This question falls in the realm of prescriptive analysis where we seek to identify the reasons behind such decline. Identifying the underlying reasons provides actionable insights into how to reverse the declining trend, as well as how to prevent such incidents from happening in the future. This will be valuable to the company in the long run.\n",
    "    \n",
    "In this question, we will focus on clients identified in Q2. We try to incorporate the external data (GDP and population) sourced in section 2, and explore its relationship with the declining clients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch one company's yearly profits and the corresponding GDP & population in the company's home country\n",
    "def get_one_profits_GDP_population(name): \n",
    "\n",
    "    c.execute('''\n",
    "    SELECT c.company, SUM(c.standardized_USD), c.year, gdp.country, gdp.value, population.value\n",
    "    FROM customer as c\n",
    "    LEFT JOIN gdp\n",
    "    On c.country = gdp.country AND c.year = gdp.year\n",
    "    LEFT JOIN population\n",
    "    ON c.country = population.country AND c.year= population.year\n",
    "    Where company = ?\n",
    "    GROUP BY company, c.year\n",
    "    ''', (name,))\n",
    "    \n",
    "    lst = c.fetchall()\n",
    "    return lst\n",
    "\n",
    "\n",
    "# fetch ALL companies' yearly profits and the corresponding GDP & population in each company's home country\n",
    "def get_multiple_profits_GDP_population(names):\n",
    "    # INPUT ARGUMENT names: a list of strings containing the company names that are of interest\n",
    "    lst = []\n",
    "    for client in names:\n",
    "        new_lst = get_one_profits_GDP_population(client)\n",
    "        lst.append(new_lst)\n",
    "    return lst    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the corresponding yearly profits, GDP and population of a client, Lajo\n",
    "get_one_profits_GDP_population(\"Lajo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the corresponding yearly profits, GDP and population of the declining clients identified in Qn2\n",
    "get_multiple_profits_GDP_population(Declining_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the yearly profits of a client and the corresponding GDP, population of the client's country of origin\n",
    "def plot_one_profits_GDP_population(name):\n",
    "    \n",
    "    lst = get_one_profits_GDP_population(name)   \n",
    "    profits = list(map(lambda x:x[1], lst))\n",
    "    year = list(map(lambda x:x[2], lst))\n",
    "    country = list(map(lambda x:x[3], lst))\n",
    "    gdp = list(map(lambda x:x[4], lst))\n",
    "    population = list(map(lambda x:x[5], lst))\n",
    "        \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15,1), sharex = True)\n",
    "    plt.subplots_adjust(wspace = 0.4, hspace = 1.5)\n",
    "    plt.xticks(year, year)\n",
    "    \n",
    "    # generate a random color from the colormap \"viridis\"\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "    colors = cmap(np.linspace(0, 1, 15))\n",
    "    rand_color = list(random.choice(colors))\n",
    "    \n",
    "    ax[0].plot(year, profits, color=rand_color)\n",
    "    ax[1].plot(year, gdp, color=rand_color)\n",
    "    ax[2].plot(year, population, color=rand_color)\n",
    "\n",
    "    ax[0].set_ylabel(\"Total Profits in USD\")\n",
    "    ax[1].set_ylabel(\"GDP\")\n",
    "    ax[2].set_ylabel(\"Population\")\n",
    "        \n",
    "    ax[0].set_title(\"Profits of {}\".format(name))\n",
    "    ax[1].set_title(\"GDP of {}\".format(country[0]))\n",
    "    ax[2].set_title(\"Population of {}\".format(country[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the yearly profits of multiple clients and the corresponding GDP, population of their countries of origin\n",
    "def plot_multiple_profits_GDP_population(names):\n",
    "    for name in names:\n",
    "        plot_one_profits_GDP_population(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the relevant information of Flipstorm\n",
    "plot_one_profits_GDP_population(\"Flipstorm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the relevant information of all declining companies\n",
    "plot_multiple_profits_GDP_population(Declining_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion 1: It can be seen that while profits of the clients are declining, GDP of these clients' countries are on the rise and populations are on the decline. We can conclude that population and profit often have a positive association while GDP and profit have a negative association. <font color='red'> However, association does not imply causation so we cannot conclude anything on the causal relationship</font>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further testify our conclusion made above, plot the remaining firms to see if the rising GDP & declining population trends apply to them. If these trends are only observed in declining firms, we can confidently conclude that GDP and population are indeed associated with declining profits. Otherwise, our conclusion may not hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the list of non-declining companies\n",
    "Non_declicing_companies = list(set(df.companies.unique()).difference(Declining_companies))\n",
    "Non_declicing_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the relevant information of all declining companies\n",
    "plot_multiple_profits_GDP_population(Non_declining_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion 2: From the plots on the non-declining companies, it can be seen that there are quite a number of companies with rising GDP and declining population, a trend that we only expect to see in the declining firms. Therefore, our final conclusion is that <font color = \"red\">there is no clear association between GDP & population and a client's profits. In other words, increase in GDP and decrease in population does not does not have a significant impact on a client's declining profits </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = \"purple\"> Q4: Which clients have lower risks than the rest? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To define low risk, our group would like to define two indicator:**\n",
    "1. Risk_Count_Fraction = Number of negative profit occurrence / Number of postive profit occurrence\n",
    "2. Risk_Amount_Fraction = Total negative profit (loss) / Total positive profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Nagetive Profits\n",
    "c.execute('''\n",
    "SELECT company, COUNT(*) as counts, SUM(standardized_USD)\n",
    "FROM customer\n",
    "Where standardized_USD < 0\n",
    "GROUP BY company\n",
    "ORDER BY company\n",
    "''')\n",
    "\n",
    "negative=c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Positive Profits\n",
    "c.execute('''\n",
    "SELECT company, COUNT(*) as counts, SUM(standardized_USD)\n",
    "FROM customer\n",
    "Where standardized_USD > 0\n",
    "GROUP BY company\n",
    "ORDER BY company\n",
    "''')\n",
    "\n",
    "positive=c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Fractions():\n",
    "    res=[]\n",
    "    nagetive_name_list=[x[0] for x in negative]\n",
    "    \n",
    "    for record in positive:\n",
    "        name = record[0]\n",
    "        positive_count=record[1]\n",
    "        positive_profit=record[2]\n",
    "        if name not in nagetive_name_list:\n",
    "            negative_count = 0\n",
    "            negative_profit = 0\n",
    "        else:\n",
    "            index=nagetive_name_list.index(name)\n",
    "            negative_count = negative[index][1]\n",
    "            negative_profit = abs(negative[index][2])\n",
    "        res.append([name,\n",
    "                    negative_count/positive_count,\n",
    "                    negative_profit/positive_profit])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first element is client name\n",
    "# the second is risk_count_fraction \n",
    "# the last is risk_amount_fraction\n",
    "risk=get_Risk_Count_Fraction()\n",
    "risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function takes in an integer and returns top N top risky client by risk_count_fraction\n",
    "def TopN_risky_count(N):\n",
    "    return sorted(risk, key=lambda x : x[1], reverse = True)[:N]\n",
    "\n",
    "# function takes in an integer and returns top N top risky client by risk_amount_fraction\n",
    "def TopN_risky_amount(N):\n",
    "    return sorted(risk, key=lambda x : x[2], reverse = True)[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try top 5\n",
    "TopN_risky_count(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try top 5\n",
    "TopN_risky_amount(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Performance\n",
    "Your boss is very impressed with what you have achieved in less than two weeks, and he would like to take your idea of storing the customer and sales data in a relational database to production. However, John is concerned that the solution will not scale. His experience is telling him that you will see many occurrences of the following queries.\n",
    "\n",
    "- Show all sales to company X between time $t_1$ and time $t_2$\n",
    "- Show the latest X sales in the database\n",
    "- Show total sales per company per day\n",
    "\n",
    "Show that Johns concern is not justified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweenTime(Company,T_start,T_end):\n",
    "    substitution=(Company,T_start,T_end)\n",
    "    \n",
    "    c.execute('''\n",
    "    SELECT part, company, country, city, date, price, standardized_USD\n",
    "    FROM customer \n",
    "    Where company = ? AND date Between ? AND ? \n",
    "    ''', substitution)\n",
    "    \n",
    "    return c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenTime('Chatterbridge','2016-01-02','2016-01-03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest(x):\n",
    "    substitution=(x,)\n",
    "    \n",
    "    c.execute('''\n",
    "    SELECT part, company, country, city, date, price, standardized_USD\n",
    "    FROM customer \n",
    "    Order BY date DESC\n",
    "    LIMIT ?\n",
    "    ''', substitution)\n",
    "    \n",
    "    return c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salesPerCompanyPerDay():\n",
    "    \n",
    "    c.execute('''\n",
    "    SELECT company, DATE(date) , SUM(standardized_USD)\n",
    "    FROM customer \n",
    "    Group BY company, Date(date)\n",
    "    ''')\n",
    "    \n",
    "    return c.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salesPerCompanyPerDay()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
